<!DOCTYPE html>
<html lang="et">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Emotsioonide Tuvastaja</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection"></script>
    <style>
        body, html {
            margin: 0;
            padding: 0;
            height: 100%;
            overflow: hidden;
        }
        video, canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        #emotionText {
            position: absolute;
            top: 20px;
            left: 20px;
            font-size: 30px;
            font-weight: bold;
            color: white;
            background-color: rgba(0, 0, 0, 0.5);
            padding: 10px;
        }
    </style>
</head>
<body>
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>
    <p id="emotionText">Tuvastamine...</p>

    <script>
        async function setupCamera() {
            const video = document.getElementById('video');
            const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "user" } });
            video.srcObject = stream;

            return new Promise((resolve) => {
                video.onloadedmetadata = () => {
                    video.play();
                    resolve();
                };
            });
        }

        async function detectEmotion() {
            const video = document.getElementById('video');
            const canvas = document.getElementById('canvas');
            const ctx = canvas.getContext('2d');

            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            const model = await faceLandmarksDetection.load(
                faceLandmarksDetection.SupportedPackages.mediapipeFacemesh,
                { maxFaces: 1 }
            );

            const emotions = {
                Happy: { color: 'yellow', text: 'Happy' },
                Angry: { color: 'red', text: 'Angry' },
                Sad: { color: 'blue', text: 'Sad' },
                Surprised: { color: 'orange', text: 'Surprised' },
                Disgusted: { color: 'green', text: 'Disgusted' },
                Fearful: { color: 'purple', text: 'Fearful' },
                Neutral: { color: 'gray', text: 'Neutral' },
            };

            setInterval(async () => {
                const predictions = await model.estimateFaces({ input: video });

                ctx.clearRect(0, 0, canvas.width, canvas.height);
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

                if (predictions.length > 0) {
                    const emotion = emotions.Neutral; // Placeholder for now, will be updated based on model
                    document.getElementById("emotionText").innerText = emotion.text;
                    document.getElementById("emotionText").style.color = emotion.color;
                } else {
                    document.getElementById("emotionText").innerText = "NÃ¤gu ei ole tuvastatud";
                }
            }, 500);
        }

        setupCamera().then(detectEmotion);
    </script>
</body>
</html>
